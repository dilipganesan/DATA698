---
title: "Data698_Modelling"
author: "Dilip Ganesan"
date: "4/3/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```



```{r, echo=FALSE, warning=FALSE, error=FALSE, cache=FALSE, results='hide', message=FALSE}

withCallingHandlers(suppressWarnings(warning("hi")), warning = function(w) {
    print(w)
})

# Loading Packages
requiredpackages <- c('knitr','psych','nlme','lattice', 'kableExtra', 'psych', 'ggplot2', 'reshape2', 'corrplot', 'tidyr', 'dplyr',  'MASS', 'caret', 'pscl', 'lmtest', 'pROC', 'ROCR','tibble','leaps','MASS','magrittr','ggplot2','glmnet','faraway','choroplethr','gridExtra','grid','aod','randomForest','nnet','neuralnet','caret')

for (i in requiredpackages){
  if(!require(i,character.only=T)) install.packages(i)
  library(i,character.only=T)
}

update_geom_defaults("point", list(size=1.5))
theme_set(theme_grey(base_size=10))

```



```{r}
#Load data set
dataset <- read.csv("https://raw.githubusercontent.com/dilipganesan/DATA698/master/Cleaned_Data/Cleaned_DATA698_Dataset.csv")
#dataset
# Cleaning the column X. 
#dataset <- dataset %>% 
dataset <-dplyr::select(dataset, - X) 

#dataset = dataset %>%
#            dplyr::select(-c("Primary_Diag","Secondary_Diag_1","Secondary_Diag_2", #"Payment","diag_1","diag_2","diag_3", "DRG")) 

dataset <- dplyr::select(dataset, - c(Primary_Diag,Secondary_Diag_1,Secondary_Diag_2, Payment,diag_1,diag_2,diag_3, DRG ) )


summary(dataset)        

# Renaming certain column namse.

# Creation of addition variables from Raghu Code.
dataset['service_utilization'] <- dataset['number_outpatient'] + 
   dataset['number_emergency'] + dataset['number_inpatient']
############ Removing some of medication data from data set because of class imbalance.
summary(dataset)
newdataset <-
            dplyr::select(dataset, c("race","gender","age", "admission_type_id","discharge_disposition_id","admission_source_id","time_in_hospital", "num_lab_procedures","num_procedures","num_medications","number_outpatient","number_emergency","number_inpatient","number_diagnoses","max_glu_serum","A1Cresult","metformin","glimepiride","glipizide","glyburide","pioglitazone","rosiglitazone","insulin","change","service_utilization","diabetesMed","readmitted","primarydiagclass","secondarydiagclass_1","tertiarydiagclass_1","DRGClassification")) 


########### Modelling
table(newdataset$readmitted )
### Checking of class bias. The number of events happening is less than events not happening. So for prepartion of dataset to be careful.
# Create Training Data
input_ones <- newdataset[which(newdataset$readmitted == 1), ]  # all 1's
input_zeros <- newdataset[which(newdataset$readmitted == 0), ]  # all 0's
set.seed(100)  # for repeatability of samples
input_ones_training_rows <- sample(1:nrow(input_ones), 0.7*nrow(input_ones))  # 1's for training
input_zeros_training_rows <- sample(1:nrow(input_zeros), 0.7*nrow(input_ones))  # 0's for training. Pick as many 0's as 1's
training_ones <- input_ones[input_ones_training_rows, ]  
training_zeros <- input_zeros[input_zeros_training_rows, ]
trainingData <- rbind(training_ones, training_zeros)  # row bind the 1's and 0's 

# Create Test Data
test_ones <- input_ones[-input_ones_training_rows, ]
test_zeros <- input_zeros[-input_zeros_training_rows, ]
testData <- rbind(test_ones, test_zeros)  # row bind the 1's and 0's 
###########################GLM####################
logitMod <- glm(readmitted ~ ., data=trainingData, family=binomial(link="logit"))

#predicted <- plogis(predict(logitMod, testData))  # predicted scores
# or
predicted <- predict(logitMod, testData, type="response")  # predicted scores
####################
predicted <- ifelse(predicted > 0.5, 1, 0)
predicted_2 <- ifelse(predicted == 1, "TRUE", "FALSE")
mean(predicted==testData$readmitted) # Accuracy: 64.6%

################Optimal Cutoff#################
library(InformationValue)
optCutOff <- optimalCutoff(testData$readmitted, predicted)[1] 
optCutOff
##############vif############
require(fmsb)
require(car)
#vif(logitMod)
##########
plotROC(testData$readmitted, predicted)
###################ConfusionMatrix#######
confusionMatrix(testData$readmitted, predicted, threshold = optCutOff)
```


```{r}
require(randomForest)
#######################Random Forrest#################
table(trainingData$readmitted )
table(testData$readmitted )

trainingData$readmitted <- ifelse(trainingData$readmitted == 1, "TRUE", "FALSE")
testData$readmitted <- ifelse(testData$readmitted == 1, "TRUE", "FALSE")
trainingData$readmitted <- as.factor(trainingData$readmitted)
testData$readmitted <- as.factor(testData$readmitted)
table(trainingData$readmitted )

model.rf1 <-randomForest(readmitted ~. , data=trainingData[,-1], ntree=10, na.action=na.exclude, importance=T,proximity=T) 

print(model.rf1) 
#model.rf2 <-randomForest(readmitted ~. , data=trainingData, ntree=20, na.action=na.exclude, importance=T,proximity=T) 
#print(model.rf2) 
#model.rf3 <-randomForest(readmitted~., data=trainingData, ntree=30, na.action=na.exclude, importance=T,proximity=T) 
#print(model.rf3) 
#model.rf4 <-randomForest(readmitted~., data=trainingData, ntree=40, na.action=na.exclude, importance=T,proximity=T) 
#print(model.rf4) 
#model.rf5 <-randomForest(readmitted~., data=trainingData, ntree=50, na.action=na.exclude, importance=T,proximity=T) 
#print(model.rf5) 
#mtry <- tuneRF(trainingData[,-1], trainingData$readmitted, ntreeTry=40,stepFactor=1.5, improve=0.01, trace=TRUE, plot=TRUE)

#model.rf <- randomForest(readmitted~., data=trainingData, ntree=40, mtry = 8, na.action=na.exclude, importance=T,proximity=T)
#pred.rf <- predict(model.rf, testData)
#mean(pred.rf==testData$readmitted) # Accuracy: 60.86%

plot(model.rf1)


```

```{r}
############################ NN Network############
require(neuralnet)
require(nnet)
model.nn <- nnet(readmitted ~., data=trainingData[,-1], size=5, maxit=1000)
pred.nn <- predict(model.nn, testData,type= "raw")
pred.nn <- ifelse(pred.nn > 0.5, "TRUE", "FALSE")
mean(pred.nn==testData$readmitted) # Accuracy: 65.61%

#plotnet(model.nn)

```


```{r}
############################ Decision Tree ############
library(rpart.plot)
require(caret)
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
dtree_fit <- train(readmitted ~., data = trainingData, method = "rpart",
                   parms = list(split = "information"),
                   trControl=trctrl,
                   tuneLength = 10)

dtree_fit
prp(dtree_fit$finalModel, box.palette = "Reds", tweak = 1.2)

#model.nn <- nnet(readmitted ~., data=trainingData[,-1], size=5, maxit=1000)
pred.nn <- predict(dtree_fit, testData,type= "raw")
#pred.nn <- ifelse(pred.nn > 0.5, "TRUE", "FALSE")
table_mat <- table(testData$readmitted,pred.nn)
table_mat
mean(pred.nn==testData$readmitted) # Accuracy: 60.8%

confusionMatrix(pred.nn, testData$readmitted )  #check accuracy

```


#Training the Decision Tree classifier with criterion as gini index

Let's try to program a decision tree classifier using splitting criterion as gini  index. It is showing us the accuracy metrics for different values of cp. Here, cp is complexity parameter for our dtree.

```{r}
set.seed(3333)
dtree_fit_gini <- train(readmitted ~., data = trainingData, method = "rpart",
                   parms = list(split = "gini"),
                   trControl=trctrl,
                   tuneLength = 10)
dtree_fit_gini

prp(dtree_fit_gini$finalModel, box.palette = "Blues", tweak = 1.2)

```

Prediction
Now, our model is trained with cp = 0.001070259 . We are ready to predict classes for our test set.
Now, it's time to predict target variable for the whole test set.

```{r}
test_pred_gini <- predict(dtree_fit_gini, newdata = testData)

table_mat <- table(testData$readmitted,test_pred_gini)
table_mat
confusionMatrix(test_pred_gini, testData$readmitted )  #check accuracy

```

